class DataModule(pl.LightningDataModule):
    def __init__(
        self,
        batch_size: int = 32,
        split_seed: int = 12345,
    ):
        super().__init__()

        self.save_hyperparameters(logger=False)
        self.full_dataset = MaskDataset()
        self.train_dataset = None
        self.val_dataset = None
        self.test_dataset = None

    def prepare_data(self):
        self.train_dataset, self.val_dataset, self.test_dataset = random_split(
            self.full_dataset, [0.8, 0.1, 0.1]
        )

    def collate(self, batch):
        return tuple(zip(*batch))

    def train_dataloader(self):
        return DataLoader(
            dataset=self.train_dataset,
            batch_size=self.hparams.batch_size,
            num_workers=multiprocessing.cpu_count(),
            shuffle=True,
        )

    def val_dataloader(self):
        return DataLoader(
            dataset=self.val_dataset,
            batch_size=self.hparams.batch_size,
            num_workers=multiprocessing.cpu_count(),
            shuffle=False,
            drop_last=False,
        )

    def test_dataloader(self):
        return DataLoader(
            dataset=self.test_dataset,
            batch_size=self.hparams.batch_size,
            num_workers=multiprocessing.cpu_count(),
            shuffle=False,
        )
